{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a561656",
   "metadata": {},
   "source": [
    "# Part 1 - Surgery Duration Prediction: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc61977",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b395899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 10000 rows x 8 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.inspection import permutation_importance as sk_perm_imp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint, uniform\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "df = pd.read_csv('surgeries to predict.csv')\n",
    "print(f'Loaded: {df.shape[0]} rows x {df.shape[1]} columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03f489",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e564ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with BMI < 10 removed: 17 (0.17%)\n",
      "Shape after cleaning: (9983, 12)\n"
     ]
    }
   ],
   "source": [
    "# Drop row index \n",
    "df_clean = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Keep raw Surgery Type for GroupMeanEncoder \n",
    "surgery_type_raw = df_clean['Surgery Type'].copy()\n",
    "\n",
    "# One hot encode surgery type and anesthesia type \n",
    "surgery_dummies    = pd.get_dummies(df_clean['Surgery Type'],   prefix='surgery',   dtype=int)\n",
    "anesthesia_dummies = pd.get_dummies(df_clean['Anesthesia Type'], prefix='anesthesia',\n",
    "                                    drop_first=True, dtype=int)\n",
    "\n",
    "df_clean = pd.concat([df_clean.drop(columns=['Surgery Type', 'Anesthesia Type']),\n",
    "                       surgery_dummies, anesthesia_dummies], axis=1)\n",
    "df_clean['surgery_type_raw'] = surgery_type_raw\n",
    "\n",
    "# drop physiologically impossible BMI rows (< 10) before any split\n",
    "mask_bad = df_clean['BMI'] < 10\n",
    "n_removed = mask_bad.sum()\n",
    "print(f'Rows with BMI < 10 removed: {n_removed} ({n_removed/len(df_clean)*100:.2f}%)')\n",
    "df_clean = df_clean[~mask_bad].reset_index(drop=True)\n",
    "\n",
    "print(f'Shape after cleaning: {df_clean.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e1ecc",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be6c1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 34\n"
     ]
    }
   ],
   "source": [
    "# Age and BMI interaction\n",
    "df_clean['age_bmi'] = df_clean['Age'] * df_clean['BMI']\n",
    "\n",
    "# Non linear transforms\n",
    "df_clean['age_sq']    = df_clean['Age'] ** 2\n",
    "df_clean['bmi_sq']    = df_clean['BMI'] ** 2\n",
    "df_clean['log1p_bmi'] = np.log1p(df_clean['BMI'])\n",
    "\n",
    "# Age and BMI buckets \n",
    "age_dummies = pd.get_dummies(\n",
    "    pd.cut(df_clean['Age'], bins=[0, 30, 45, 60, np.inf],\n",
    "           labels=['age_lt30', 'age_30_45', 'age_45_60', 'age_60plus']), dtype=int)\n",
    "bmi_dummies = pd.get_dummies(\n",
    "    pd.cut(df_clean['BMI'], bins=[0, 18.5, 25, 30, 35, np.inf],\n",
    "           labels=['bmi_under18', 'bmi_18_25', 'bmi_25_30', 'bmi_30_35', 'bmi_35plus']), dtype=int)\n",
    "df_clean = pd.concat([df_clean, age_dummies, bmi_dummies], axis=1)\n",
    "\n",
    "# Surgery and patient interactions \n",
    "surgery_cols = [c for c in df_clean.columns\n",
    "                    if c.startswith('surgery_') and c != 'surgery_type_raw']\n",
    "for col in surgery_cols:\n",
    "    df_clean[f'{col}_x_age'] = df_clean[col] * df_clean['Age']\n",
    "    df_clean[f'{col}_x_bmi'] = df_clean[col] * df_clean['BMI']\n",
    "\n",
    "print(f'Total features: {df_clean.shape[1] - 1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b5826",
   "metadata": {},
   "source": [
    "## 4. Custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ed68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Replaces each ID with its count in the training fold (no leakage).\"\"\"\n",
    "    def __init__(self, columns): self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        self.frequency_maps_ = {col: X[col].value_counts().to_dict() for col in self.columns}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            X[col] = X[col].map(self.frequency_maps_[col]).fillna(0).astype(int)\n",
    "        return X\n",
    "\n",
    "\n",
    "class GroupMeanEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Fold safe target encoding: adds mean per group value, drops raw column.\"\"\"\n",
    "    def __init__(self, columns): self.columns = columns\n",
    "    def fit(self, X, y):\n",
    "        y_arr = np.asarray(y, dtype=float)\n",
    "        self.global_mean_ = float(y_arr.mean())\n",
    "        self.mean_maps_ = {}\n",
    "        for col in self.columns:\n",
    "            tmp = pd.DataFrame({'g': np.asarray(X[col]), 'y': y_arr})\n",
    "            self.mean_maps_[col] = tmp.groupby('g')['y'].mean().to_dict()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            X[f'{col}_mean_duration'] = X[col].map(self.mean_maps_[col]).fillna(self.global_mean_)\n",
    "            X = X.drop(columns=[col])\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcef1c5",
   "metadata": {},
   "source": [
    "## 5. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc9c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS       = ['DoctorID', 'AnaesthetistID']\n",
    "MEAN_ENC_COLS = ['surgery_type_raw']\n",
    "\n",
    "X = df_clean.drop(columns=['Duration in Minutes'])\n",
    "y = df_clean['Duration in Minutes']\n",
    "groups = X['DoctorID']   # GroupKFold:the same DoctorID never appears in both train and validation\n",
    "\n",
    "def make_pipeline(model, scale=False):\n",
    "    steps = [('freq_enc', FrequencyEncoder(columns=ID_COLS)),\n",
    "             ('mean_enc', GroupMeanEncoder(columns=MEAN_ENC_COLS))]\n",
    "    if scale: steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "models = {\n",
    "    'Random Forest':     make_pipeline(RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n",
    "    'Gradient Boosting': make_pipeline(HistGradientBoostingRegressor(max_iter=200, random_state=42)),\n",
    "    'XGBoost':           make_pipeline(XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1, verbosity=0)),\n",
    "    'Ridge Regression':  make_pipeline(Ridge(alpha=1.0), scale=True),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22391d2b",
   "metadata": {},
   "source": [
    "## 6. Default 5-Fold GroupKFold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fc267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: MAE=17.39, Acc±15=49.25%\n",
      "Gradient Boosting: MAE=16.14, Acc±15=49.66%\n",
      "XGBoost: MAE=16.91, Acc±15=49.31%\n",
      "Ridge Regression: MAE=15.94, Acc±15=49.54%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE (min)</th>\n",
       "      <th>MAE std</th>\n",
       "      <th>MAPE (%)</th>\n",
       "      <th>Acc ±15min (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>17.39</td>\n",
       "      <td>0.26</td>\n",
       "      <td>20.68</td>\n",
       "      <td>49.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>16.14</td>\n",
       "      <td>0.30</td>\n",
       "      <td>19.30</td>\n",
       "      <td>49.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>16.91</td>\n",
       "      <td>0.29</td>\n",
       "      <td>20.14</td>\n",
       "      <td>49.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>15.94</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.81</td>\n",
       "      <td>49.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MAE (min)  MAE std  MAPE (%)  Acc ±15min (%)\n",
       "Random Forest          17.39     0.26     20.68           49.25\n",
       "Gradient Boosting      16.14     0.30     19.30           49.66\n",
       "XGBoost                16.91     0.29     20.14           49.31\n",
       "Ridge Regression       15.94     0.20     19.81           49.54"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = GroupKFold(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for model_name, pipeline in models.items():\n",
    "    fold_mae, fold_mape, fold_acc15 = [], [], []\n",
    "    for train_idx, val_idx in kf.split(X, y, groups):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "        preds = pipeline.predict(X_val)\n",
    "        fold_mae.append(np.mean(np.abs(preds - y_val)))\n",
    "        fold_mape.append(np.mean(np.abs((preds - y_val) / y_val)) * 100)\n",
    "        fold_acc15.append(np.mean(np.abs(preds - y_val) <= 15) * 100)\n",
    "    results[model_name] = {\n",
    "        'MAE (min)':      round(np.mean(fold_mae),   2),\n",
    "        'MAE std':        round(np.std(fold_mae),    2),\n",
    "        'MAPE (%)':       round(np.mean(fold_mape),  2),\n",
    "        'Acc ±15min (%)': round(np.mean(fold_acc15), 2),\n",
    "    }\n",
    "    print(f'{model_name}: MAE={results[model_name][\"MAE (min)\"]}, Acc±15={results[model_name][\"Acc ±15min (%)\"]}%')\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1fd06",
   "metadata": {},
   "source": [
    "## 7. RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f13bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: best CV MAE=15.90\n",
      "Gradient Boosting: best CV MAE=15.88\n",
      "XGBoost: best CV MAE=15.80\n",
      "Ridge Regression: best CV MAE=15.95\n"
     ]
    }
   ],
   "source": [
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'model__n_estimators':      randint(100, 500),\n",
    "        'model__max_depth':         [None, 10, 20, 30],\n",
    "        'model__min_samples_split': randint(2, 20),\n",
    "        'model__min_samples_leaf':  randint(1, 10),\n",
    "        'model__max_features':      ['sqrt', 'log2', 0.5],\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model__max_iter':           randint(100, 400),\n",
    "        'model__learning_rate':      uniform(0.01, 0.29),\n",
    "        'model__max_depth':          [3, 5, 7, None],\n",
    "        'model__min_samples_leaf':   randint(10, 50),\n",
    "        'model__l2_regularization':  uniform(0.0, 2.0),\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators':    randint(100, 500),\n",
    "        'model__learning_rate':   uniform(0.01, 0.29),\n",
    "        'model__max_depth':       randint(3, 10),\n",
    "        'model__subsample':       uniform(0.6, 0.4),\n",
    "        'model__colsample_bytree': uniform(0.6, 0.4),\n",
    "        'model__reg_alpha':       uniform(0.0, 2.0),\n",
    "        'model__reg_lambda':      uniform(0.5, 2.5),\n",
    "    },\n",
    "    'Ridge Regression': {'model__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},\n",
    "}\n",
    "\n",
    "search_cv = GroupKFold(n_splits=3)\n",
    "best_params_found = {}\n",
    "for model_name, pipeline in models.items():\n",
    "    search = RandomizedSearchCV(pipeline, param_grids[model_name], n_iter=20,\n",
    "                                scoring='neg_mean_absolute_error', cv=search_cv,\n",
    "                                random_state=42, n_jobs=-1, refit=False)\n",
    "    search.fit(X, y, groups=groups)\n",
    "    best_params_found[model_name] = search.best_params_\n",
    "    print(f'{model_name}: best CV MAE={-search.best_score_:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eaca2a",
   "metadata": {},
   "source": [
    "## 8. Tuned Models (5-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15422884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   MAE (min)  MAPE (%)  Acc ±15min (%)\n",
      "Random Forest          15.85     18.96           49.48\n",
      "Gradient Boosting      15.78     19.00           49.75\n",
      "XGBoost                15.74     18.92           49.99\n",
      "Ridge Regression       15.94     19.81           49.54\n"
     ]
    }
   ],
   "source": [
    "eval_cv = GroupKFold(n_splits=5)\n",
    "tuned_results  = {}\n",
    "tuned_pipelines = {}\n",
    "\n",
    "for model_name, pipeline in models.items():\n",
    "    tuned_pipeline = clone(pipeline)\n",
    "    tuned_pipeline.set_params(**best_params_found[model_name])\n",
    "    tuned_pipelines[model_name] = tuned_pipeline\n",
    "    fold_mae, fold_mape, fold_acc15 = [], [], []\n",
    "    for train_idx, val_idx in eval_cv.split(X, y, groups):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        tuned_pipeline.fit(X_tr, y_tr)\n",
    "        preds = tuned_pipeline.predict(X_val)\n",
    "        fold_mae.append(np.mean(np.abs(preds - y_val)))\n",
    "        fold_mape.append(np.mean(np.abs((preds - y_val) / y_val)) * 100)\n",
    "        fold_acc15.append(np.mean(np.abs(preds - y_val) <= 15) * 100)\n",
    "    tuned_results[model_name] = {\n",
    "        'MAE (min)':      round(np.mean(fold_mae),   2),\n",
    "        'MAE std':        round(np.std(fold_mae),    2),\n",
    "        'MAPE (%)':       round(np.mean(fold_mape),  2),\n",
    "        'Acc ±15min (%)': round(np.mean(fold_acc15), 2),\n",
    "    }\n",
    "\n",
    "tuned_df = pd.DataFrame(tuned_results).T\n",
    "print(tuned_df[['MAE (min)', 'MAPE (%)', 'Acc ±15min (%)']].to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75bfa1",
   "metadata": {},
   "source": [
    "## 9. Log Target Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32bf9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   MAE (min)  MAPE (%)  Acc ±15min (%)\n",
      "Random Forest          15.92     18.41           49.57\n",
      "Gradient Boosting      15.87     18.43           49.66\n",
      "XGBoost                15.82     18.34           49.86\n",
      "Ridge Regression       16.04     19.05           49.92\n"
     ]
    }
   ],
   "source": [
    "log_results = {}\n",
    "for model_name, tuned_pipeline in tuned_pipelines.items():\n",
    "    log_model = TransformedTargetRegressor(regressor=clone(tuned_pipeline),\n",
    "                                           func=np.log1p, inverse_func=np.expm1)\n",
    "    fold_mae, fold_mape, fold_acc15 = [], [], []\n",
    "    for train_idx, val_idx in eval_cv.split(X, y, groups):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        log_model.fit(X_tr, y_tr)\n",
    "        preds = log_model.predict(X_val)\n",
    "        fold_mae.append(np.mean(np.abs(preds - y_val)))\n",
    "        fold_mape.append(np.mean(np.abs((preds - y_val) / y_val)) * 100)\n",
    "        fold_acc15.append(np.mean(np.abs(preds - y_val) <= 15) * 100)\n",
    "    log_results[model_name] = {\n",
    "        'MAE (min)':      round(np.mean(fold_mae),   2),\n",
    "        'MAPE (%)':       round(np.mean(fold_mape),  2),\n",
    "        'Acc ±15min (%)': round(np.mean(fold_acc15), 2),\n",
    "    }\n",
    "\n",
    "log_df = pd.DataFrame(log_results).T\n",
    "print(log_df[['MAE (min)', 'MAPE (%)', 'Acc ±15min (%)']].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0918513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "MODEL COMPARISON ACROSS ALL EVALUATIONS\n",
      "====================================================================================================\n",
      "\n",
      "Accuracy Comparison (±15 min) - Higher is Better:\n",
      "                   Tuned (Step 8)  Log Transform (Step 9)  Improvement\n",
      "Ridge Regression            49.54                   49.92         0.38\n",
      "XGBoost                     49.99                   49.86        -0.13\n",
      "Gradient Boosting           49.75                   49.66        -0.09\n",
      "Random Forest               49.48                   49.57         0.09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare all evaluations\n",
    "print(\"=\" * 100)\n",
    "print(\"MODEL COMPARISON ACROSS ALL EVALUATIONS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Tuned (Step 8)': tuned_df['Acc ±15min (%)'],\n",
    "    'Log Transform (Step 9)': log_df['Acc ±15min (%)'],\n",
    "    'Improvement': log_df['Acc ±15min (%)'] - tuned_df['Acc ±15min (%)'],\n",
    "})\n",
    "comparison_df = comparison_df.sort_values('Log Transform (Step 9)', ascending=False)\n",
    "print(\"\\nAccuracy Comparison (±15 min) - Higher is Better:\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138a0fa",
   "metadata": {},
   "source": [
    "## 10. Feature Importance (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "setg7w580r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: XGBoost  |  Acc ±15min: 49.99%\n"
     ]
    }
   ],
   "source": [
    "# Select best model (highest Acc ±15min across tuned and log-transform runs)\n",
    "best_acc_tuned  = tuned_df['Acc ±15min (%)'].max()\n",
    "best_acc_log    = log_df['Acc ±15min (%)'].max()\n",
    "use_log         = best_acc_log >= best_acc_tuned\n",
    "best_model_name = (log_df if use_log else tuned_df)['Acc ±15min (%)'].idxmax()\n",
    "best_acc        = max(best_acc_tuned, best_acc_log)\n",
    "config_label    = f'{best_model_name} + log(y)' if use_log else best_model_name\n",
    "print(f'Best model: {config_label}  |  Acc ±15min: {best_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de4c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance method: built-in\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "surgery_2                         0.445338\n",
      "surgery_type_raw_mean_duration    0.277390\n",
      "surgery_0                         0.216386\n",
      "surgery_0_x_age                   0.018986\n",
      "age_60plus                        0.012683\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit best pipeline on all data (without log transform)\n",
    "best_pipeline_final = clone(tuned_pipelines[best_model_name])\n",
    "best_pipeline_final.fit(X, y)\n",
    "\n",
    "# Also fit log-transform version\n",
    "final_model = TransformedTargetRegressor(\n",
    "    regressor=clone(best_pipeline_final),\n",
    "    func=np.log1p, inverse_func=np.expm1\n",
    ")\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Extract feature importances\n",
    "model_step = best_pipeline_final.named_steps['model']\n",
    "X_preprocessed = best_pipeline_final[:-1].transform(X)\n",
    "feature_names = list(X_preprocessed.columns) if hasattr(X_preprocessed, 'columns') \\\n",
    "                else [f'f{i}' for i in range(X_preprocessed.shape[1])]\n",
    "\n",
    "if hasattr(model_step, 'feature_importances_'):\n",
    "    method = 'built-in'\n",
    "    feat_imp = pd.Series(model_step.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "else:\n",
    "    method = 'permutation'\n",
    "    result = sk_perm_imp(best_pipeline_final, X, y, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "    feat_imp = pd.Series(result.importances_mean, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(f\"Feature importance method: {method}\")\n",
    "print(f\"\\nTop 5 Most Important Features:\")\n",
    "print(feat_imp.head(5).to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ecdedc",
   "metadata": {},
   "source": [
    "## 11. Save Results to `results/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a06f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to results/:\n",
      "  best_model.joblib  (673,215 bytes)\n",
      "  best_model_info.json  (696 bytes)\n",
      "  default_results.csv  (195 bytes)\n",
      "  feature_importances.csv  (857 bytes)\n",
      "  log_results.csv  (170 bytes)\n",
      "  tuned_results.csv  (196 bytes)\n"
     ]
    }
   ],
   "source": [
    "# DataFrames\n",
    "results_df.to_csv('results/default_results.csv')\n",
    "tuned_df.to_csv('results/tuned_results.csv')\n",
    "log_df.to_csv('results/log_results.csv')\n",
    "feat_imp.to_frame('importance').to_csv('results/feature_importances.csv')\n",
    "\n",
    "def to_python(v):\n",
    "    if isinstance(v, np.bool_):    return bool(v)\n",
    "    if isinstance(v, np.integer):  return int(v)\n",
    "    if isinstance(v, np.floating): return float(v)\n",
    "    return v\n",
    "\n",
    "# Best model metadata\n",
    "meta = {\n",
    "    'best_model_name': str(best_model_name),\n",
    "    'config_label':    str(config_label),\n",
    "    'use_log':         bool(use_log),\n",
    "    'best_acc':        float(best_acc),\n",
    "    'method':          str(method),\n",
    "    'best_params':     {k: to_python(v) for k, v in best_params_found[best_model_name].items()},\n",
    "    'top5':            {str(k): float(v) for k, v in feat_imp.head(5).items()},\n",
    "}\n",
    "with open('results/best_model_info.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "# Fitted best model \n",
    "save_model = final_model if use_log else best_pipeline_final\n",
    "joblib.dump(save_model, 'results/best_model.joblib')\n",
    "\n",
    "print('Saved to results/:')\n",
    "for fname in sorted(os.listdir('results')):\n",
    "    size = os.path.getsize(f'results/{fname}')\n",
    "    print(f'  {fname}  ({size:,} bytes)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
